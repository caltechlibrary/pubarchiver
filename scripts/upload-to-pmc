#!/bin/bash
# =============================================================================
# @file    upload-to-pmc
# @brief   Script meant to be run from cron
# @author  Michael Hucka <mhucka@caltech.edu>
# @license Please see the file named LICENSE in the project directory
# @website https://github.com/caltechlibrary/pubarchiver
#
# Principles:
#
#  0. The Python environment and the location of pubarchiver and the "slack"
#     CLI utility are configured in the account running this program. (Mainly
#     this means "pubarchiver" and "slack" are commands in the $PATH.)
#
#  1. The frequency of archives is set by the cron schedule, not in here.
#
#  2. The local output directory where files are saved is set by environment
#     variable PMC_OUTPUT.
#
#  3. A timestamp file is created in the output directory, and pubarchiver
#     is run with that date stamp as the "after date" argument.
#
#  4. Archives are created in subdirectories of the output directory named
#     after the date+time they were done.  E.g., "2019-08-29-1000".
#
#  5. A report file is written to the output directory and named "report.csv".
#
#  6. A log file is written to the output directory and named "run.log".
#
#  7. Archived articles are uploaded to ftp://ftp-private.ncbi.nlm.nih.gov/
#     using ftp credentials that are passed via environment variables
#     PMC_USER and PMC_PASS.
#
#  8. Outcomes are emailed to the comma-separated addresses in environment
#     variable $EMAIL_SUCCESS or $EMAIL_FAILURE, depending on whether
#     execution succeed or failed, respectively.  They are also posted to the
#     Slack channel set by environment vaiable SLACK_CHANNEL using API token
#     SLACK_CLI_TOKEN.  (Note: SLACK_CLI_TOKEN is read by the command
#     `slack`, which is why it does not appear used below.)
#
# =============================================================================

# Store the path to this script so we can report it in error messages.
mainscript=${BASH_SOURCE[0]}

# Files recording the results of the most recent run are stored at the level
# of the directory indicatd by $PMC_OUTPUT, because this information is
# carried across runs.
today=$(date +%Y-%m-%d)
datestampfile=$PMC_OUTPUT/last-run-date

# Today's run will be written in a subdirectory.  Note the subdirectory name
# includes the current time, not just today's date, because otherwise we
# would overwrite the previous data if we ran run multiple times per day.
now=$(date +%Y-%m-%d-%H%M)
outputdir=$PMC_OUTPUT/$now

# Each run produces several log and record files in $outputdir.
log=$outputdir/run.log
report=$outputdir/report.csv
debuglog=$outputdir/debug.log


# Define helper functions ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

scriptdir="$(cd -P -- "$(dirname -- "$mainscript")" && pwd -P)"
source $scriptdir/helpers.sh


# Do the real work ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

# Before doing anything else, create the output directory.
mkdir -p $outputdir

# Start by recording the current time.
echo "Starting at $now" >> $log
echo "" >> $log

# Read the date stamp from the previous run.
if [[ -e $datestampfile ]]; then
    read afterdate < $datestampfile
    # Go back one day to include the run date in the argument given to
    # pubarchiver's --after-date (or else we miss the day of the run itself).
    afterdate=$(date -d "$afterdate -1 days" +"%Y-%m-%d")
else
    # We've never run, or someone reset the date stamp.
    # Use a fake date that basically signifies "since forever".
    afterdate="1900-01-01"
fi

echo "=== Running pubarchiver for articles since $afterdate ===" >> $log
echo "" >> $log
# This will get all articles since the last successful run.  If there were
# any failures, they will be tried again as a result of this, because we
# don't upload and don't update the last-run date if there are any failures.
run_pubarchiver -j micropublication -d pmc -C -a $afterdate -o $outputdir \
                -r $report -@ $debuglog

# Did we have validation failures?  Notify someone specifically about that.
lines=$(egrep 'validation|missing|failed' $report | wc -l)
if [[ $lines -gt 0 ]]; then
    echo "The attached run log may provide clues about the errors." | \
    mail -s "PMC upload stopped $today due to errors in $lines articles" \
         -a $report -a $log $EMAIL_FAILURE

    run_slack chat send --channel $SLACK_CHANNEL --color "#ff0000" \
          --title "Error: did not upload micropublication.org to PMC" \
          --text "Pubarchiver stopped PMC upload due to errors in $lines articles"
    run_slack file upload --channels $SLACK_CHANNEL --file "$log" \
          --comment "Here is the pubarchiver run log"
else
    # If we didn't have validation errors, ftp any new archives to PMC.
    # Note: curl has weird syntax for sending multiple files at once.
    lines=$(grep complete $report | wc -l)
    if [[ $lines -gt 0 ]]; then
        echo "" >> $log
        echo "=== FTP'ing file using curl ===" >> $log
        run_curl --retry 5 --user $PMC_USER:$PMC_PASS \
            -T "{$(echo $outputdir/micropublication-org/*.zip | tr ' ' ',')}" \
            ftp://ftp-private.ncbi.nlm.nih.gov/
    fi

    # If we get this far, write out a date stamp file to indicate that things
    # ran successfully and to give the next run a starting point.
    echo $today > $datestampfile

    # Send email about the results.
    grep -F "Total articles" $log | sed 's/ left after filtering//g' | \
        mail -s "PMC upload results for $today" -A $report -A $log $EMAIL_SUCCESS

    # Post the report to Slack.

    run_slack chat send --channel $SLACK_CHANNEL --color "#00ff00" \
        --title "pubarchiver successfully completed PMC upload"
    run_slack file upload --channels $SLACK_CHANNEL --file $report \
        --comment "Here is the record of what was uploaded:"
fi
